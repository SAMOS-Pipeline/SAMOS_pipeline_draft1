%% This is emulateapj reformatting of the AASTEX sample document
%%
%\documentclass[onecolumn]{aastex62}
\documentclass{aastex}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{mathdots}



%\newcommand{\vdag}{(v)^\dagger}
%\newcommand{\myemail}{koeppeda@msu.edu}

%% You can insert a short comment on the title page using the command below.

\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand{\code}{\texttt}


\begin{document}


\section{Introduction}

%\textbf{This is the master branch, which does not presently include cosmic ray cleaning.  Please see the branch Cosmic_ray_dev.}


The main content of the directories the user should have in his or her working directory for the current version of the pipeline is shown below:


\begin{itemize}
  \setlength{\itemsep}{0.3\baselineskip}
  \item \code{SAMOS-working-dir/}:
        \begin{itemize}
          \setlength{\itemsep}{0.1\baselineskip}
          \item[$\ast$] \code{cleaner.sh}
          \item[$\ast$] \code{Docs/}
          \item[$\ast$] Readme.md
          \item[$\ast$] \code{LDSS3/}
          \item[$\ast$] \code{helper$\_$files/}
          \item[$\ast$] \code{linelists/}
          \item[$\ast$] \code{py$\_$mods/}
        \end{itemize}
  \item \code{SAMOS-working-dir/py$\_$mods/}:
        \begin{itemize}
          \setlength{\itemsep}{0.1\baselineskip}
          \item[$\ast$] \code{CreateFuelStructure.py}
          \item[$\ast$] \code{CreateInput.py}
          \item[$\ast$] \code{CreateSlitStructure.py}
          \item[$\ast$] \code{FlatNorm.py}
          \item[$\ast$] \code{InitializeSAMOS.py}
          \item[$\ast$] \code{NormDivFlats.py}
          \item[$\ast$] \code{OutlineSlits.py}
          \item[$\ast$] \code{Overscan.py}
          \item[$\ast$] \code{OverscanAndTrim.py}
          \item[$\ast$] \code{SAMOSHelpers.py}
          \item[$\ast$] \code{SlitCutout.py}
          \item[$\ast$] \code{SlitID.py}
          \item[$\ast$] \code{$\_\_$init$\_\_$.py}
        \end{itemize}
  \item \code{SAMOS-working-dir/helper$\_$files}:
        \begin{itemize}
          \setlength{\itemsep}{0.1\baselineskip}
          \item[$\ast$] LMask1.SMF
          \item[$\ast$] LMask2.SMF
          \item[$\ast$] LMask1$\_$ycoords$\_$c1.txt
          \item[$\ast$] LMask2$\_$ycoords$\_$c1.txt
          \item[$\ast$] LMask2$\_$ycoords$\_$red$\_$c1.txt
        \end{itemize}
\end{itemize}




Right now, there are 4 main programs that the user runs to reduce data.  WhichFITSFiles, OverscanAndTrim, NormDivFlats, and `OutlineSlits.

This document reviews the purpose and describes how to use these programs to reduce the test data from LDSS3.  Eventually, it will be used to reduce multi-object spectroscopy data taken with the SOAR Adaptive-Module Optical Spectrograph (SAMOS).  For information on the instrument, see \href{https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9908/1/SAMOS--a-versatile-multi-object-spectrograph-for-the-GLAO/10.1117/12.2233094.full}{(Robberto et al. 2016)}.  In order to avoid reinventing the wheel, this pipeline is heavily based on the \href{https://github.com/siriobelli/flame}{Flame DRP} written by \href{https://arxiv.org/pdf/1710.05924.pdf}{Belli, Contursi, and Davies (2017)}.  Flame is written in IDL, while the SAMOS pipeline will be written in Python3.

\section{\code{WhichFITSFiles}}

This program retrieves the headers from the sample data in \textbf{LDSS3/2017-11-30/} and separates them into a directory corresponding to one two masks \textbf{LMask1} and \textbf{LMask2}, that the user decides.  It also reads the header keys to determine whether the file contains flat data, comparison lamp data, or science data, and stores it in database files named for their corresponding LMask.

To run this code, it takes two arguments, the name of the directory with the test data (date on which data was retrieved) and the mask for which the user wants to use.  Running this code for LMask1 data would look like:

\begin{verbatim}
  >./WhichFITSFiles 2017-11-30 LMask1
\end{verbatim}

After running and reading over the terminal output, you should have a new directory named \textbf{LMask1} and a new file named \textbf{LMask1.db}.  This step also now keeps track of the field image.  The FITS headers for the test LDSS3 data do not contain the slit positions, so having the image of the actual slit mask is necessary at this time.  The slit mask information is contained in the files LMask1.SMF and LMask2.SMF.  The explanation for these files can be found on the Carnegie Observatories website, \href{http://code.obs.carnegiescience.edu/maskgen/v213/smdfile.txt/view}{here}.

\section{\code{OverscanAndTrim}}


Next, we have to determine the overscan and trim the edges of the fits data. This code reads the database file and creates arrays which separate the data into flats, comparison lamps, and science data.

The main part of \code{OverscanAndTrim} is the calling of the module \code{Overscan.py}.  This module parses the fits data array into regions of bias and target data by reading the fits headers BIASSEC and DATASEC respectively.  There is a function in \code{Overscan.py} called \code{FieldTrim(\ldots)} that trims the field mask to the correct size.  Then, I looked in DS9 for the top edges of each of the slits and made a text file of the positions which will be used in the step \code{OutlineSlits}.  The function responsible for trimming and bias subtraction of the other FITS files is \code{Overscan(\ldots)}.

The bias is due to a combination of the camera noise from the readout process and electric ``pre-charge'' on a CCD chip by the electronics.  The BIASSEC header gives the region of overscan, which contains information for this bias.  An array of this overscan region is made by grabbing the rows and columns from the data array (\code{d = f[0].data.astype(``f'')} $\rightarrow$ \code{overscan = d[biassec rows, biassec columns]}). The function then takes the median (or mean) of the overscan regions along the rows (axis=1), and subtracts these values from each data value in their respective data rows.  The main procedure is shown in the figure below.

$$
 \begin{pmatrix}
  cropped & and\\\
  bias & subtraced\\\
  data & matrix
 \end{pmatrix} =
 \begin{pmatrix}
 d11 & d12 & d13 & ... & d1m\\\
 d21 & d22 & ... & ... & d2m\\\
 ... & ... & ... & ... & ...\\\
 dn1 & ... & ... & ... & dnm
 \end{pmatrix} -
 \begin{pmatrix}
  [b1]\\\
  [b2]\\\
  [b3]\\\
  [...]\\\
  [bn]
 \end{pmatrix}
$$


With the new data matrix, the function makes a new FITS file for the files originally entered as input.  The output FITS are placed in their respective LMask directories and the `ccd' part of their original file names are replaced with LMask(1,2).

To run this step, type

\begin{verbatim}
> ./OverscanAndtrim LMask(1,2).db
\end{verbatim}


\section{\code{NormDivFlats}}

Once we have our cropped and bias subtracted fits files, we need to locate and combine the flat frames into one master flat, which will be divided from the science frames.
First we make a stack of the flat field frames and scale them by their median.  then the stack is median combined and normalized, which gives the pixel-to-pixel variation in detector sensitivity.
The function outputs a fits file named LMask(1,2)master$\_$flat.  Finally, the science frames are divided by the master flat and written out to new frames, which are placed in a directory named  \textbf{flat$\_$fielded}.

To call this routine, use
\begin{verbatim}
> ./NormDivFlats LMask(1,2).db
\end{verbatim}

The function also creates thumbnail images of the output data frames.



\section{\code{OutlineSlits}}

Since the headers for the test data do not contain slit information, I typed up a text file of slit positions called \textbf{LMask(1,2)$\_$ycoords$\_$c1.txt}.  This file contains the top edge pixel for each of the slits in the field image.  The module \code{Slit$\_$id.py} contains the function \code{get$\_$edges(\ldots)}, which is responsible for tracing the slits, using the master flat output from \code{NormDivFlats} as a template.  \code{get$\_$edges} takes the master flat and the slit positions text file as input.  The function steps along cutouts of the FITS data frame based on the y-axis positions given in the text.  For each step, the median of the cutout along the x-axis is taken, and then the derivative along the y-axis is computed to locate the transition from the chip to the slid edge.  This steps along the slit until it reaches the end, storing the x and y positions.  The arrays of slit positions are written to a region file called \textbf{reg$\_$txt.reg} within the corresponding mask directory, and can be loaded into DS9.  An example of this for LMask2 is shown in figure \ref{fig:regtxt}.  The slits outlined here are representative of the slits found in the image of the mask field, so not all of the slits in a science image will be included in this step.

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.7]{region_file_ex}
  \caption{\textbf{LMask2/reg$\_$txt.reg} overlayed onto science image in DS9.}\label{fig:regtxt}
\end{figure}

To run this step, use

\begin{verbatim}
  > ./OutlineSlits LMask(1,2).db
\end{verbatim}

\section{TL;DR}

This is the most up to date version of the documentation for the SAMOS pipeline thus far.  Currently, there is no main script to run all the processes at once, so the user will have to run them step by step.  To summarize, the user input for data reduction up to and including slit identification is,

\begin{equation}
  \begin{split}
    &\code{> ./WhichFITSFiles 2017-11-30 LMask*}\\
    &\code{> ./OverscanAndTrim LMask*.db}\\
    &\code{> ./NormDivFlats LMask*.db}\\
    &\code{> ./OutlineSlits LMask*.db}
  \end{split}
\end{equation}

\end{document}
